# Importing necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error
from statsmodels.stats.outliers_influence import variance_inflation_factor
import statsmodels.api as sm

# Load the dataset
data = pd.read_csv("day.csv")

# Displaying the first few rows of the dataset
print(data.head())

# Checking for null values
print(data.isnull().sum())

# Data Preprocessing: Converting numeric columns to categorical
data['season'] = data['season'].map({1: 'Spring', 2: 'Summer', 3: 'Fall', 4: 'Winter'})
data['weathersit'] = data['weathersit'].map({
    1: 'Clear/Partly Cloudy',
    2: 'Mist/Cloudy',
    3: 'Light Snow/Rain',
    4: 'Heavy Rain/Snow'
})

# Dropping unnecessary columns
data = data.drop(['instant', 'dteday', 'casual', 'registered'], axis=1)

# Creating dummy variables for categorical columns
data = pd.get_dummies(data, drop_first=True)

# Splitting data into features and target
X = data.drop(['cnt'], axis=1)
y = data['cnt']

# Splitting the dataset into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Function to calculate Variance Inflation Factor (VIF)
def calculate_vif(dataframe):
    # Ensure all columns are numeric
    dataframe = dataframe.select_dtypes(include=[np.number])
    vif_data = pd.DataFrame()
    vif_data["Feature"] = dataframe.columns
    vif_data["VIF"] = [
        variance_inflation_factor(dataframe.values, i) for i in range(dataframe.shape[1])
    ]
    return vif_data

# Checking for non-numeric columns
print("Data types of X_train:")
print(X_train.dtypes)

# Ensure all columns in X_train are numeric
X_train = X_train.apply(pd.to_numeric, errors='coerce')

# Drop rows with missing values (if any)
X_train = X_train.dropna()
y_train = y_train.loc[X_train.index]  # Align `y_train` with `X_train`

# Calculate VIF
print("VIF before feature selection:")
print(calculate_vif(X_train))

# Building the linear regression model using scikit-learn
lr = LinearRegression()
lr.fit(X_train, y_train)

# Making predictions
y_train_pred = lr.predict(X_train)
y_test_pred = lr.predict(X_test)

# Evaluating the model
train_r2 = r2_score(y_train, y_train_pred)
test_r2 = r2_score(y_test, y_test_pred)
mse = mean_squared_error(y_test, y_test_pred)

print(f"Train R-squared: {train_r2}")
print(f"Test R-squared: {test_r2}")
print(f"Mean Squared Error: {mse}")

# Residual Analysis
residuals = y_test - y_test_pred
sns.histplot(residuals, kde=True)
plt.title("Residual Distribution")
plt.show()

# Scatter plot of residuals
plt.scatter(y_test_pred, residuals)
plt.axhline(y=0, color='r', linestyle='--')
plt.xlabel("Predicted Values")
plt.ylabel("Residuals")
plt.title("Residuals vs Predicted Values")
plt.show()

# Using Statsmodels for detailed summary
X_train_sm = sm.add_constant(X_train)
model = sm.OLS(y_train, X_train_sm).fit()
print(model.summary())

# Displaying VIF after feature selection
print("VIF after feature selection:")
print(calculate_vif(X_train))
